import os
import cv2
import numpy as np
import torch

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé˜²æ­¢è‡ªåŠ¨ä¸‹è½½æ¨¡å‹
os.environ['YOLO_VERBOSE'] = '0'
os.environ['ULTRALYTICS_HUB_OFFLINE'] = '1'

def optimize_bbox_for_hand(x1, y1, x2, y2):
    """
    ä¼˜åŒ–è¾¹ç•Œæ¡†ï¼Œä¸“æ³¨äºæ‰‹éƒ¨è€Œéæ‰‹è‡‚åŒºåŸŸ
    ä½¿ç”¨åŸºäºæ‰‹éƒ¨å‡ ä½•ç‰¹å¾çš„ç®—æ³•æ¥ç²¾ç¡®å®šä½æ‰‹éƒ¨
    """
    # è®¡ç®—åŸå§‹è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹å’Œå°ºå¯¸
    width = x2 - x1
    height = y2 - y1
    center_x = x1 + width // 2
    center_y = y1 + height // 2
    
    # æ‰‹éƒ¨å‡ ä½•åˆ†æï¼š
    # 1. æ‰‹éƒ¨é€šå¸¸å…·æœ‰æ›´ç´§å‡‘çš„ç»“æ„ï¼Œè€Œæ‰‹è‡‚åˆ™æ˜¯å»¶ä¼¸çš„
    # 2. å…¸å‹çš„æ‰‹éƒ¨è¾¹ç•Œæ¡†åº”è¯¥æ›´åŠ æ–¹å½¢ï¼Œè€Œä¸æ˜¯ç‹­é•¿çš„çŸ©å½¢
    aspect_ratio = width / height
    
    # åŸºäºé•¿å®½æ¯”çš„ä¼˜åŒ–ç­–ç•¥
    if aspect_ratio < 0.6:  # è¾ƒçª„çš„è¾¹ç•Œæ¡†ï¼Œå¯èƒ½æ˜¯æ‰‹è‡‚ä¼¸å±•çŠ¶æ€
        # å‡è®¾æ‰‹éƒ¨ä½äºé è¿‘æœ«ç«¯çš„ä½ç½®ï¼ˆé€šå¸¸æ˜¯åº•éƒ¨ï¼‰
        # å°†è¾¹ç•Œæ¡†é‡ç‚¹æ”¾åœ¨æ£€æµ‹æ¡†çš„ä¸‹åŠéƒ¨åˆ†
        hand_section = 0.4  # æ‰‹éƒ¨å æ•´ä¸ªæ£€æµ‹æ¡†çš„æ¯”ä¾‹
        new_height = int(height * hand_section)
        new_width = int(width * 0.8)  # é€‚å½“æ”¶ç¼©å®½åº¦
        
        # ä»åº•éƒ¨å‘ä¸Šå®šä½æ‰‹éƒ¨
        new_y2 = y2
        new_y1 = max(0, new_y2 - new_height)
        new_x1 = max(0, center_x - new_width // 2)
        new_x2 = new_x1 + new_width
    
    elif aspect_ratio > 1.5:  # è¾ƒå®½çš„è¾¹ç•Œæ¡†ï¼Œå¯èƒ½æ˜¯æ‰‹æŒå±•å¼€
        # æ‰‹æŒé€šå¸¸æ›´åŠ æ–¹å½¢ï¼Œæ‰€ä»¥è°ƒæ•´ä¸ºæ›´æ¥è¿‘æ–¹å½¢çš„æ¯”ä¾‹
        target_height = int(width * 1.2)  # ç¨å¾®é«˜ä¸€äº›
        target_height = min(target_height, height)  # ä¸è¶…è¿‡åŸå§‹é«˜åº¦
        
        # ç¡®ä¿è¾¹ç•Œæ¡†é›†ä¸­åœ¨æ‰‹æŒåŒºåŸŸ
        new_width = int(width * 0.7)  # æ”¶ç¼©å®½åº¦
        new_height = target_height
        
        # ä»ä¸­å¿ƒå®šä½
        new_x1 = max(0, center_x - new_width // 2)
        new_x2 = new_x1 + new_width
        new_y1 = max(0, center_y - new_height // 2)
        new_y2 = new_y1 + new_height
    
    else:  # ä¸­ç­‰é•¿å®½æ¯”ï¼Œæ¥è¿‘æ–¹å½¢
        # é’ˆå¯¹æ›´å¯èƒ½æ˜¯æ‰‹éƒ¨çš„æƒ…å†µï¼Œä½¿ç”¨æ›´å°çš„æ”¶ç¼©æ¯”ä¾‹
        # æ‰‹éƒ¨é€šå¸¸åœ¨æ£€æµ‹æ¡†çš„ä¸­ä¸‹éƒ¨
        hand_center_factor = 0.65  # å°†ä¸­å¿ƒç‚¹å‘ä¸‹ç§»åŠ¨
        hand_center_y = y1 + int(height * hand_center_factor)
        
        # æ”¶ç¼©å°ºå¯¸
        new_width = int(width * 0.65)
        new_height = int(height * 0.65)
        
        # é‡æ–°å®šä½è¾¹ç•Œæ¡†
        new_x1 = max(0, center_x - new_width // 2)
        new_x2 = new_x1 + new_width
        new_y1 = max(0, hand_center_y - new_height // 2)
        new_y2 = new_y1 + new_height
    
    # ç¡®ä¿è¾¹ç•Œæ¡†ä¸ä¼šè¿‡åº¦ç¼©å°
    min_size = 50  # æœ€å°å°ºå¯¸é˜ˆå€¼
    if (new_x2 - new_x1) < min_size:
        expand = (min_size - (new_x2 - new_x1)) // 2
        new_x1 = max(0, new_x1 - expand)
        new_x2 = new_x1 + min_size
    
    if (new_y2 - new_y1) < min_size:
        expand = (min_size - (new_y2 - new_y1)) // 2
        new_y1 = max(0, new_y1 - expand)
        new_y2 = new_y1 + min_size
    
    return new_x1, new_y1, new_x2, new_y2

def detect_hand_in_image(model, image_path, output_suffix):
    """
    ä½¿ç”¨æ¨¡å‹æ£€æµ‹å•å¼ å›¾ç‰‡ä¸­çš„æ‰‹
    """
    print(f"\nå¤„ç†å›¾ç‰‡: {image_path}")
    
    # è¯»å–å›¾ç‰‡
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return None, False
    
    print(f"âœ… æˆåŠŸè¯»å–å›¾ç‰‡")
    
    # ç›´æ¥è°ƒç”¨æ¨¡å‹çš„é¢„æµ‹æ–¹æ³•
    print(f"ğŸ”„ æ­£åœ¨è¿›è¡Œæ¨¡å‹æ¨ç†...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    results = model.predict(source=image, conf=0.5, device=device, verbose=False)
    
    # å¤„ç†ç»“æœ
    result_image = image.copy()
    detected = False
    
    if len(results) > 0 and len(results[0].boxes) > 0:
        detected = True
        # è·å–ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹æ¡†
        boxes = results[0].boxes
        max_conf_idx = np.argmax(boxes.conf.cpu().numpy())
        
        # æå–åŸå§‹è¾¹ç•Œæ¡†ä¿¡æ¯
        orig_x1, orig_y1, orig_x2, orig_y2 = map(int, boxes.xyxy[max_conf_idx].cpu().numpy())
        conf = float(boxes.conf[max_conf_idx].cpu().numpy())
        
        # ä¼˜åŒ–è¾¹ç•Œæ¡†ï¼Œèšç„¦äºæ‰‹éƒ¨
        opt_x1, opt_y1, opt_x2, opt_y2 = optimize_bbox_for_hand(orig_x1, orig_y1, orig_x2, orig_y2)
        
        # ç»˜åˆ¶åŸå§‹è¾¹ç•Œæ¡†ï¼ˆè“è‰²è™šçº¿ï¼‰
        cv2.rectangle(result_image, (orig_x1, orig_y1), (orig_x2, orig_y2), (255, 0, 0), 2, cv2.LINE_AA)
        
        # ç»˜åˆ¶ä¼˜åŒ–åçš„è¾¹ç•Œæ¡†ï¼ˆç»¿è‰²å®çº¿ï¼‰
        cv2.rectangle(result_image, (opt_x1, opt_y1), (opt_x2, opt_y2), (0, 255, 0), 2, cv2.LINE_AA)
        
        # æ·»åŠ æ ‡ç­¾
        label = f"Hand: {conf:.2f}"
        cv2.putText(result_image, label, (opt_x1, max(0, opt_y1-10)), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
        
        print(f"âœ… æ£€æµ‹åˆ°æ‰‹ï¼")
        print(f"  - åŸå§‹ä½ç½®: ({orig_x1}, {orig_y1}) åˆ° ({orig_x2}, {orig_y2})")
        print(f"  - ä¼˜åŒ–åä½ç½®: ({opt_x1}, {opt_y1}) åˆ° ({opt_x2}, {opt_y2})")
        print(f"  - ç½®ä¿¡åº¦: {conf:.2f}")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°æ‰‹")
    
    # ä¿å­˜ç»“æœ
    output_path = os.path.join("..", f"simple_hand_detection_result_{output_suffix}.jpg")
    cv2.imwrite(output_path, result_image)
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    return result_image, detected

def main():
    """
    ç®€åŒ–ç‰ˆæ‰‹éƒ¨æ£€æµ‹è„šæœ¬ - ç›´æ¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œè¯†åˆ«
    ç°åœ¨åŒæ—¶æ£€æµ‹test1.jpgå’Œtest2.jpeg
    """
    print("====== æ‰‹éƒ¨æ£€æµ‹ (ç›´æ¥ä½¿ç”¨æ¨¡å‹) ======\n")
    
    # 1. åŠ è½½YOLOæ¨¡å‹
    print("æ­£åœ¨åŠ è½½è®­ç»ƒå¥½çš„æ‰‹éƒ¨æ£€æµ‹æ¨¡å‹...")
    try:
        from ultralytics import YOLO
        
        # ä½¿ç”¨é¡¹ç›®ä¸­è®­ç»ƒå¥½çš„æ¨¡å‹
        model_path = os.path.join("..", "models", "output", "hand_detection_model", "weights", "best.pt")
        
        if os.path.exists(model_path):
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹: {model_path}")
            model = YOLO(model_path)  # ç›´æ¥åŠ è½½æ¨¡å‹
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        else:
            print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}")
            print("ä½¿ç”¨é»˜è®¤YOLOv8næ¨¡å‹...")
            model = YOLO("yolov8n.pt")
            print("âœ… é»˜è®¤æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # 2. å‡†å¤‡æ£€æµ‹çš„å›¾ç‰‡åˆ—è¡¨ - åŒ…æ‹¬test1å’Œtest2
    print("\nå‡†å¤‡æ£€æµ‹å›¾ç‰‡...")
    image_paths = [
        (os.path.join("..", "test1.jpg"), "test1"),
        (os.path.join("..", "test2.jpeg"), "test2")
    ]
    
    result_images = []
    
    # 3. å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹
    for image_path, suffix in image_paths:
        if os.path.exists(image_path):
            result_img, detected = detect_hand_in_image(model, image_path, suffix)
            if result_img is not None:
                result_images.append((result_img, suffix))
        else:
            print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    # 4. æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
    if result_images:
        print("\næ˜¾ç¤ºæ£€æµ‹ç»“æœ (æŒ‰ä»»æ„é”®å…³é—­æ¯ä¸ªçª—å£)...")
        for img, suffix in result_images:
            cv2.imshow(f"æ‰‹éƒ¨æ£€æµ‹ç»“æœ - {suffix}", img)
            cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    print("\n====== æ‰€æœ‰å›¾ç‰‡æ£€æµ‹å®Œæˆ ======")
    print(f"æ€»å…±å¤„ç†å›¾ç‰‡æ•°: {len(result_images)}")
    print(f"ç»“æœæ–‡ä»¶ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•")

if __name__ == "__main__":
    main()